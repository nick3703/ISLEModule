---
title: "Is a sub 2 hour marathon in the near future?  Modeling rare events in sports."
author: Rodney X. Sturdivant, Ph.D., Baylor University and Nick Clark, Ph.D., West
  Point
output:
  beamer_presentation: default
header-includes:
- \usepackage{caption}
- \captionsetup[figure]{labelformat=empty}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = F, message = F)
```

```{r package loading, include=FALSE}
library(tidyverse);theme_set(theme_minimal()); theme_update(text = element_text(family = "serif"))
library(ggplot2)
library(MASS)
library(Hmisc)
library(DescTools)
library(goftest)
library(readr)
library("hawkesbow")
library(readr)
library(MASS)
library(lubridate)
library(kableExtra)
```

# Outline

- Baseball Rare Events (if needed only)

- Background

- Marathon Data

- Simple Model

- Self-Exciting Model

- Further Research

- SCORE 

# Background

<center>
![Golden Age?](NYTIMESarticle.png){width=50%}

</center>

## Are we living in a time of records?
- Idea:  seems like an increase in records falling, but is it just the nature of randomness?

## How can we address this question?
## What would randomness look like?

# 

::: columns

:::: column

![Rod Aloha 10K Run (San Diego, 2018), 2nd Age Group](aloharun.jpg){width=90%}
::::
:::: column
![Rod Last Marathon (LA, 2018), 1st, Glendora CA Runners](RodLAmarathon.png){height=60%}
::::
::: 

# Marathon World Record Data

Men's Marathon world records since 1908

```{r}
record_table_mod<-read_rds("record_table_mod.rds")
days_between = as.numeric(diff(record_table_mod$Date_ymd))
daysfromstart <- cumsum(days_between)
daysfromstart <- c(0,daysfromstart)  ### get data in terms of days from first record (time 0)
  # units of year
daysfromstart_mod2 <- daysfromstart/365 
days_between_mod2 = diff(daysfromstart_mod2)

```

- 50 total

- First 5

`r knitr::kable(record_table_mod[1:5,1:5]) %>%
  kable_styling(font_size = 7)`
  
- Last 5

`r knitr::kable(record_table_mod[46:50,1:5]) %>%
  kable_styling(font_size = 7)`

# Visualizing the data

- Two and three hour times shown as horizontal lines
```{r, fig.align='center', out.width="75%"}
td<-seconds_to_period(c(7500,8500,9500,10500))
timelabs <- sprintf('%02d:%02d:%02d', td@hour, minute(td), 
                                   round(second(td)))
p1<-plot(record_table_mod$Date_ymd, record_table_mod$Time_t, 
         type = "h", xlab = "Data (YMD)", ylab = "Record (H:M:S)", 
         yaxt = "n", ylim = c(7100,10800))
axis(2, at = c(7500,8500,9500,10500), labels = timelabs, 
     cex.axis = 0.75)
abline(a = 7200, b = 0, lty = 2, col = "red" )
abline(a = 3*60*60, b = 0, lty = 2, col = "red" )
```
- 2 hour marathon pace: 4:35 per mile

- 3 hour pace:  6:52 per mile




# SOME MARATHON RECORD HOLDER STORIES/INFO


MAYBE INCLUDE A COUPLE OF PICTURES OF PEOPLE

ADD SOME SUMMARY STUFF - TRIVIA: COUNTRIES, LOCATIONS OF MARATHON ETC


# SIMPLE MODEL

## POISSON PROCESS 

A model for a series of discrete events where the average time between events is known, but the exact timing of events is "random" meeting the following criteria: 

-  Events are independent of each other. The occurrence of one event does not affect the probability another event will occur.

-  The average rate (events per time period) is constant.

-  Two events cannot occur at the same time.

# Poisson Process Interarrival Times

The time between events (known as the interarrival times) follow an exponential distribution defined as:

$$P(T>t) = e^{-\lambda t}$$

- T is the random variable of the time until the next event

- t is a specific time for the next event

- $\lambda$ is the rate:  the average number of events per unit of time.  

Note the possible values of T are greater than 0 (positive only).  


# Reasonableness of Exponential Interarrivals

The exponential distribution has certain attributes, for example:

\begin{center}
$E(T) = SD(T) = 1/\lambda$
\end{center}

\vspace{12pt}

For the time between record data:

- Mean: `r round(mean(days_between_mod2),2)` years

- SD: `r round(sd(days_between_mod2),2)` years

Reasonable...slightly "overdispersed"


#  Estimating the Model

We estimate (MLE) 
$\lambda = 1/E(T)$ = `r round(fitdistr(days_between_mod2,"exponential")$estimate,3)`


```{r}
expfit=fitdistr(days_between_mod2,"exponential")
exprate<-expfit$estimate

x=density(days_between_mod2)
hist(days_between_mod2,main="Histogram, density curve and exponential model",xlab="Interarrival Time",freq=FALSE,ylim=c(0,0.5))
lines(x,col="red",lty = 2, lwd = 2)
curve(dexp(x, rate = exprate),col=3, lty = 3, lwd = 2, add = TRUE)

```





# Graphical Assessment of Fit



```{r}
x=seq(0,max(days_between_mod2),0.1)
plot(x,pexp(x,rate=exprate),type="l",col="red", main="EDF and Exponential CDF",xlab="Interarrival Time",ylab="Proportion <= x")
Ecdf(days_between_mod2,xlab='Interarrival Times',subtitle=FALSE,add=TRUE)
```

# Testing Model Fit 

## Goodness of fit tests
\vspace{12pt}
- Kolmogorov-Smirnov:  p = `r round(ks.test(days_between_mod2,pexp,rate=exprate)$p.value,3)`

- Cramer-Von Mises:  p = `r round(cvm.test(days_between_mod2,pexp,rate=exprate)$p.value,3)`

- Anderson-Darling:  p = `r round(ad.test(days_between_mod2,pexp,rate=exprate)$p.value,3)`

\vspace{12pt}
All fail to reject the null hypothesis of model fit

# Are records then random?

```{r}

PlotQQ(days_between_mod2, function(p) qexp(p, rate=exprate), main = "QQ Plot of Exponential Model")

```

# What are the poorly fit points?

- 11.5 year gap

`r knitr::kable(record_table_mod[16:17,1:5]) %>%
  kable_styling(font_size = 7)`


- 10.4 year gap

`r knitr::kable(record_table_mod[40:41,1:5]) %>%
  kable_styling(font_size = 7)`



# A "Self-Exciting" Model

## Self-Exciting Point Processes

- Events "trigger" more events

- Examples of use include earthquakes, crime waves

## Hawkes Processes

- Let $H_t$ be the history of events up to time $t$.  The Hawkes (1971) model of the conditional intensity is:

$$\lambda(t|H_t) = \nu + \sum_{i:t_i<t} g(t - t_i)$$
where $\nu$ is the background rate of events and g is the "triggering function".

# Exponential Triggering Function

- The "triggering" function can be further decomposed:

$$g = \mu g^*$$
where $g^*$ is a density function known as the "reproduction kernel" and $\mu$ is known as the "reproduction" mean.  

- A common choice for the "reproduction kernel" is the exponential density given by:

$$g^*(t) = \beta e^{-\beta t} $$

# Fitting the model


```{r}
set.seed(1234)
optMarathon<-mle(daysfromstart_mod2,"Exponential",110.23)  # end date picked number greater than longest times
nu = optMarathon$par[1]
mu = optMarathon$par[2]
b = optMarathon$par[3]

```

Parameter estimates for marathon data (exponential) Hawkes process, using MLE: 

- baseline intensity  `r round(nu,3)`
- reproduction mean  `r round(mu,3)`
- exponential reproduction function rate `r round(b,3)`

Note the baseline intensity is slightly lower than the constant model rate estimate of `r round(exprate,3)`

The estimated reproduction function is then: 

$$g(t) = \mu g^*(t) = \mu \beta e^{-\beta t} $$
$$ = `r round(mu,2)` * `r round(b,2)` e^{-`r round(b,2)` t} $$

# Model implications

```{r}
rate0=mu*b
```


At the instant of the first event (world record), $t = t_1$ so $g(t - t_1 = 0)$ and the reproduction rate is:

$$g(0) = `r round(mu,2)` * `r round(b,2)` e^{-`r round(b,2)` 0} = `r round(mu,2)` * `r round(b,2)` =  `r round(rate0,3)` $$

- The rate increases from the baseline rate of `r round(nu,3)` by this amount at the moment of this occurrence

- The rate then decays back to baseline over time (unless a new event occurs).

- Each new event "excites" the rate to increase and then decay

# The Intensity Function over Time

The intensity function gives the value of the rate at any time

Below is a simulation for 100 year period based on the fitted model.

- The rate is at the baseline of `r round(nu,3)` until a new event occurs

- We see the jump in rate with each new event

- The rate decays to baseline unless another event happens


```{r, out.width="75%"}
set.seed(777)
simRecs_Hawkes <- hawkes(100, fun = optMarathon$par[1], repr = optMarathon$par[2], family = "exp", rate = optMarathon$par[3]) 

plot(simRecs_Hawkes, intensity = TRUE, xlab = "Time (Years)")

```

# How Fast is the rate "decay"

- Within 1 year essentially return to baseline

```{r}

t1 <- seq(0,1,0.01)
plot(t1, mu*b*exp(-b*t1), xlab = "Time Since Event (Years)", 
     ylab = "Increase in Intensity above Baseline")

```


# Process as "Generations"

- An event (1st generation) may spur immediate new event (2nd generation)...etc

- Cannot truly identify in our data; below is simulated

```{r}
plot(simRecs_Hawkes, intensity = FALSE)
```

# Inference for parameter estimates

- Ogata (1971) asymptotic result

$$M^{1/2}(\hat{\theta}_M - \theta_o) \xrightarrow{d} N(0, I(\theta_o)^{-1})$$

$$-M^{-1}H_M(\theta_o) \xrightarrow{p} I(\theta_o)$$
# Estimated Ogata confidence intervals

- 95% confidence intervals based on Ogata for the three model parameters

```{r}
#optMarathon$model$ddloglik(daysfromstart_mod2, optMarathon$end)
hessian<-optMarathon$model$ddloglik(daysfromstart_mod2, optMarathon$end)
infomat<- -1*hessian/optMarathon$end
varcov<-solve(infomat)
#varcov
se1<-sqrt(varcov[1,1])/sqrt(optMarathon$end)
se2<-sqrt(varcov[2,2])/sqrt(optMarathon$end)
se3<-sqrt(varcov[3,3])/sqrt(optMarathon$end)
nu.ll<-round(nu,3)-qnorm(0.975)*se1
nu.ul<-round(nu,3)+qnorm(0.975)*se1
mu.ll<-round(mu,3)-qnorm(0.975)*se2
mu.ll<-round(mu,3)+qnorm(0.975)*se2
b.ll<-round(b,3)-qnorm(0.975)*se3
b.ll<-round(b,3)+qnorm(0.975)*se3
```

- baseline intensity  `r round(nu,3)`

  `r round(nu,3)`
- reproduction mean  `r round(mu,3)`
- exponential reproduction function rate `r round(b,3)`


# Intensity Functions for Both Models 

- The Hawkes intensity function is the model applied to the actual data

- The function for the Poisson model is a constant rate of `r round(exprate,3)`

```{r}

base_x<-seq(0,114,.01)
base_y<-rep(nu,length(base_x))
 
base_y_exc <- mu*b*exp(-b*base_x)+base_y
 
excite <- base_y
for(j in 1:length(daysfromstart_mod2)){
  for(i in 1:length(base_x)){
    if(daysfromstart_mod2[j]>base_x[i]){
      excite[i] <- excite[i]+0
    }else{
      excite[i] <- excite[i]+mu*b*exp(-b*(base_x[i]-daysfromstart_mod2[j]))
    }
  }
}
 
plot(base_x,excite,type="l",ylim=c(0,2),col="red", 
     xlab = "Time (years since 1908)", ylab = "Conditional Intensity")
points(daysfromstart_mod2,rep(0,length(daysfromstart_mod2)), pch=3)

abline(a = exprate, b = 0, lty = 2, col = "blue")

```


# The Compensator Function

- Integrated intensity function...cumulative rate

- Simple example:  constant intensity with rate 2 per year

- Compensator grows at constant rate (linear)

```{r, figures-side, fig.show="hold", out.width="40%"}

par(mar = c(4, 4, .1, .1))
plot(c(0,1,2),c(2,2,2), type = "l", xlab = "Time (Years)", 
     ylab = "Conditional Intensity")

plot(c(0,1,2),c(0,2,4), type = "l", xlab = "Time (Years)", 
     ylab = "Compensator Function")

```

# Arrivals Exactly on Schedule

- Two arrivals per year spaced perfectly at 6 months

- Values of compensator for points 1, 2, 3, 4 are 1, 2, 3, 4

- Compensator values at arrivals are "residuals"; if "on schedule" Poisson process with rate 1

```{r, out.width="80%"}

plot(c(0,1,2),c(0,2,4), type = "l", xlab = "Time (Years)", 
     ylab = "Compensator Function")
points(c(0.5,1,1.5,2),c(1,2,3,4), cex = 2, pch = 3, col = "blue")

```

# "Residuals" based on Compensator

- Suppose actual arrivals still constant but 3 per year (model is 2 per year)

- Residuals below the y = x (Poisson rate 1) line

```{r, fig.show="hold", out.width="40%"}

plot(c(0,1,2),c(0,2,4), type = "l", xlab = "Time (Years)", 
     ylab = "Compensator Function")
points(c(0.33,0.67,1,1.33,1.67,2),2*c(0.33,0.67,1,1.33,1.67,2),
       cex = 2, pch = 3, col = "blue" )

plot(c(1:6),c(1:6), type = "l", xlab = "Event Number", 
     ylab = "Residuals")
points(c(1:6),2*c(0.33,0.67,1,1.33,1.67,2),
       cex = 2, pch = 3, col = "blue" )

```

# Compensator Function for Fitted Hawkes Model

```{r}
compensate<-compensator(daysfromstart_mod2, t=0:111, fun = optMarathon$par[1], 
                        repr = optMarathon$par[2], family = "exp", rate = optMarathon$par[3])
plot(c(0:111),compensate, type = "l", xlab = "Time (Years since 1908)",
     ylab = "Compensator")
points(daysfromstart_mod2,rep(0,length(daysfromstart_mod2)), pch=3)
```


# "Self Exciting" Portion of Compensator Function 

- We remove the baseline (cumulative) rate to better see the Hawkes process

```{r}

compensate<-compensator(daysfromstart_mod2, t=0:111, fun = optMarathon$par[1], 
                        repr = optMarathon$par[2], family = "exp", rate = optMarathon$par[3])
plot(c(0:111),compensate-optMarathon$par[1]*seq(0,111), type = "l", 
     xlab = "Time (Years since 1908)", ylab = "Self-excite Portion of Compensator")
points(daysfromstart_mod2,rep(0,length(daysfromstart_mod2)), pch=3)

```

# Residuals for Fitted Hawkes Model

-  Arrivals at times "faster" than model

- Jump up event 17:  1947 record (after 12 year gap)

- Jump up event 41:  1998 record (after 10 year gap)

```{r}
resid<-residuals(daysfromstart_mod2, fun = optMarathon$par[1], repr = optMarathon$par[2], 
                  family = "exp", rate = optMarathon$par[3],
                 xlab = "Event Number", ylab = "Residuals")
plot(resid)
abline(0, 1, col="red", lty="dashed")

```



# Constant Rate Model Compensator and Residuals

```{r, fig.show="hold", out.width="40%"}

compensate_const<-compensator(daysfromstart_mod2, t=0:111, fun = exprate, repr = 0, 
                        family = "exp", rate = 0)
plot(c(0:111),compensate_const, type = "l",
     xlab = "Time (Years since 1908)", ylab = "Compensator")
resid_const<-residuals(daysfromstart_mod2, fun = exprate, repr = 0, 
                 family = "exp", rate = 0)
plot(resid_const, xlab = "Event Number", ylab = "Residuals")
abline(0, 1, col="red", lty="dashed")


```

# Comparing Model Residuals

- Hawkes generally "better" 

- Two large gaps clear impact on both models

- Hard to tell degree of improvement

```{r, out.width="80%"}
plot(resid_const, xlab = "Event Number", ylab = "Residuals")
abline(0, 1, col="red", lty="dashed")
points(resid, col ="blue", pch = 4)
legend(1, 45, legend=c("Constant Rate", "Hawkes"),
       col=c("black", "blue"), pch=c(1,4))

```




# Comparing Models - Overdispersion

::: columns

:::: column

![](VarianceMeanPoisson.jpg){width=100%}

::::

:::: column

![](VarianceMeanHawkes.jpg){width=100%}

::::

:::


# Conclusions

- Men's marathon records reasonably modeled using Poisson process

- Some indication a "self-exciting" process could explain arrivals better

- As times get faster harder to break the record?

- Two "outlier" periods impact the models


# Further Work...

- Explore models for other events: women's marathon, other distances, swimming

- Develop better metrics to compare and assess models


# SCORE

Here several slides - the overall project - the module for this work (at whatever point we can get it...)


# References

Data source: Wikipedia (https://en.wikipedia.org/wiki/Marathon_world_record_progression) scraped August 12, 2022

Poisson process:
https://towardsdatascience.com/the-poisson-distribution-and-poisson-process-explained-4e2cb17d459

Hawkes, Alan G. 1971. “Spectra of Some Self-Exciting and Mutually Exciting Point Processes.” Biometrika
58 (1): 83–90. https://doi.org/10.2307/2334319.

Ogata, Y. (1981). On Lewis' simulation method for point processes.IEEE Trans-
actions on Information Theory, 27(1), 23-31.

"Hawkesbow" package...

